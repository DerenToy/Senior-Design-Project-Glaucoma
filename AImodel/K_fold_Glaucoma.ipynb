{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K_fold_Glaucoma.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_UDm0yEZvz"
      },
      "source": [
        "# Glaucoma Prediction\n",
        "Glaucoma is an eye disease and it causes permanent vision damage when the diagnosis is made late."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D012NAIuorMu",
        "outputId": "5aa6e262-125f-440b-c536-459831412b23"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SawgnLjllZt",
        "outputId": "15a972b8-b3e6-4f9b-b071-8e084b8e3f63"
      },
      "source": [
        "cd '/content/drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsvlI2mlluxv"
      },
      "source": [
        "root_path = \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqsdF0XQos_l"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgKtTVe4ooDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b272798-0c4f-4763-ff4c-41057bbc6329"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "from tensorflow.keras.models  import load_model\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnJCDGu4o5r-"
      },
      "source": [
        "datasetFolderName=root_path+'KFoldACRIMA'\n",
        "MODEL_FILENAME=root_path+\"model_cv.h5\"\n",
        "sourceFiles=[]\n",
        "classLabels=['glaucoma', 'healthy']\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "img_rows, img_cols =  100, 100 # input image dimensions\n",
        "train_path=datasetFolderName+'/train/'\n",
        "validation_path=datasetFolderName+'/validation/'\n",
        "test_path=datasetFolderName+'/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk22FJ2lo980"
      },
      "source": [
        "def transferBetweenFolders(source, dest, splitRate): \n",
        "    global sourceFiles\n",
        "    sourceFiles=os.listdir(source)\n",
        "    if(len(sourceFiles)!=0):\n",
        "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
        "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
        "        for eachIndex in transferIndex:\n",
        "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "        \n",
        "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
        "    for label in classLabels:\n",
        "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
        "                               datasetFolderName+'/'+dest+'/'+label+'/', \n",
        "                               splitRate)\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    accuracy=accuracy_score(y_true, y_pred)\n",
        "    precision=precision_score(y_true, y_pred,average='weighted')\n",
        "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1Score))\n",
        "    cm=confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1Score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutTsY_KpIts"
      },
      "source": [
        "# First, check if test folder is empty or not, if not transfer all existing files to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnuEdnTo-CL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a767efbf-f794-45d1-b1d8-abc2b370c49a"
      },
      "source": [
        "transferAllClassBetweenFolders('test', 'train', 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No file moved. Source empty!\n",
            "No file moved. Source empty!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf_j9bHZpMp0"
      },
      "source": [
        "# Now, split some part of train data into the test folders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlTUXCNbEXZT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySOvsWMZpPFl"
      },
      "source": [
        "transferAllClassBetweenFolders('train', 'test', 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_6tNUr8pw1b"
      },
      "source": [
        "def prepareNameWithLabels(folderName):\n",
        "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n",
        "    for val in sourceFiles:\n",
        "        X.append(val)\n",
        "        for i in range(len(classLabels)):\n",
        "          if(folderName==classLabels[i]):\n",
        "              Y.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABR_vPykp6Fx"
      },
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(classLabels)):\n",
        "  prepareNameWithLabels(classLabels[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct4KgEXpp8vz"
      },
      "source": [
        "X=np.asarray(X)\n",
        "Y=np.asarray(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrlZd93LqAOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f69e5c-9794-42a9-8c28-0c4075e4a23f"
      },
      "source": [
        "# Note that, this model structure is a very basic one. To achieve better performance, you should change the model structure and hyperparameters according to your needs and data.\n",
        "batch_size = 512\n",
        "epoch=100\n",
        "activationFunction='elu'\n",
        "def getModel():\n",
        "    vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
        "    model = Sequential()\n",
        "    for layer in vgg16_model.layers[:-1]:\n",
        "      model.add(layer)\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    return model\n",
        "\n",
        "model=getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 16s 0us/step\n",
            "553476096/553467096 [==============================] - 16s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "644hpu2kqMvF"
      },
      "source": [
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(Adam(learning_rate=.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HV84D6Kqfoc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_h0Kviqfqp"
      },
      "source": [
        "# **Stratified K-Fold Cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8Eey7KqgqUez",
        "outputId": "f38b30be-42da-4565-d32a-2f10119c727e"
      },
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "foldNum=0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    #First cut all images from validation to train (if any exists)\n",
        "    transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
        "    foldNum+=1\n",
        "    print(\"Results for fold\",foldNum)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for eachIndex in range(len(X_val)):\n",
        "        classLabel=''\n",
        "        for i in range(len(classLabels)):\n",
        "          if(Y_val[eachIndex]==i):\n",
        "              classLabel=classLabels[i]\n",
        "        #Then, copy the validation images to the validation folder\n",
        "        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
        "                    datasetFolderName+'/validation/'+classLabel+'/'+X_val[eachIndex])\n",
        "        \n",
        "    train_datagen = ImageDataGenerator(\n",
        "                      rescale=1./255,\n",
        "                      zoom_range=0.20,\n",
        "                      fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        \n",
        "    #Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)   \n",
        "   \n",
        "    # fit model\n",
        "    history=model.fit(train_generator, \n",
        "                        epochs=50)\n",
        "    \n",
        "    predictions = model.predict_generator(validation_generator, verbose=1)\n",
        "    yPredictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")    \n",
        "    valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Found 374 images belonging to 2 classes.\n",
            "Found 187 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-bb3c378700f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     history=model.fit(train_generator, \n\u001b[0;32m---> 46\u001b[0;31m                         epochs=50)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 1723392 values, but the requested shape requires a multiple of 25088\n\t [[node sequential/flatten/Reshape (defined at <ipython-input-31-667b5b46536b>:49) ]] [Op:__inference_train_function_1623]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEHXwyb7zI1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvIlpPcxqaf3"
      },
      "source": [
        "# Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doo1xZFqqW1H",
        "outputId": "b1f5aa95-49ba-48e7-8ffd-ce8a914008f0"
      },
      "source": [
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False) \n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "yPredictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "testAcc,testPrec, testFScore = my_metrics(true_classes, yPredictions)\n",
        "model.save(MODEL_FILENAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============TEST RESULTS============\n",
            "Found 139 images belonging to 2 classes.\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Accuracy  : 0.9568345323741008\n",
            "Precision : 0.9570662114376295\n",
            "f1Score : 0.9567480193060741\n",
            "[[76  2]\n",
            " [ 4 57]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0XGZsXz6mHy"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, \n",
        "                          normalize=False,\n",
        "                         title = 'Confusion Matrix',\n",
        "                         cmap=plt.cm.Blues):\n",
        "  \n",
        "  plt.imshow(cm, interpolation = 'nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation = 45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  thresh = cm.max() / 2.\n",
        "  \n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j,i, cm[i,j],\n",
        "            horizontalalignment =\"center\",\n",
        "            color = \"white\" if cm[i,j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfNQ8WhI6u_q"
      },
      "source": [
        "cm = confusion_matrix(true_classes, yPredictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUgXRRao6whS"
      },
      "source": [
        "cm_plot_labels = ['Glaucoma', 'Healthy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "SAT2vp226yZr",
        "outputId": "f0338e78-ce67-4f33-f43c-10b0f61f0179"
      },
      "source": [
        "plot_confusion_matrix(cm, cm_plot_labels,title ='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}